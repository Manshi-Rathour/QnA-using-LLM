{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9393bd01",
   "metadata": {},
   "source": [
    "# Basic working of Google Palm LLM in LangChain\n",
    "\n",
    "#### Get API key for Google Palm llm: https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1e9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain_community \n",
    "from langchain.llms import GooglePalm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "llm = GooglePalm(google_api_key=api_key, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f780870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Oh, samosa, my love**\n",
      "**You are so delicious, so flaky**\n",
      "**With your filling of potatoes and peas**\n",
      "**I could eat you every day**\n"
     ]
    }
   ],
   "source": [
    "poem = llm(\"Write a 4 line poem of my love for samosa\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa48680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Name of Customer Service Representative],\n",
      "\n",
      "I am writing to request a refund for the [product name] that I purchased on [date]. I am not satisfied with the product because [explain why you are not satisfied].\n",
      "\n",
      "I have attached a copy of my receipt and a picture of the product. I have also included a link to the product's listing on your website.\n",
      "\n",
      "I would like to request a full refund for the product. I would also like to request that you send me a replacement product.\n",
      "\n",
      "I would appreciate it if you could process my refund as soon as possible. I can be reached at [email address] or [phone number] if you have any questions.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "essay = llm(\"write email requesting refund for electronic item\")\n",
    "print(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afac9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152248c",
   "metadata": {},
   "source": [
    "# Step 1: Load data from Codebasics FAQ csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb3a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='codebasics_faqs.csv', source_column=\"prompt\")\n",
    "\n",
    "# Store the loaded data in the 'data' variable\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742fdc2f",
   "metadata": {},
   "source": [
    "# Step 2 : Text Embedding using HuggingFace InstructEmbeddings \n",
    "\n",
    "#### https://python.langchain.com/v0.1/docs/integrations/text_embedding/instruct_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e90811e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797ddcdd4b2b4b3ea188fc7a65439947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c26b0554d684e6dad5036e7fad92646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb0219012004b2194f9355a2643928f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61cfb1e0f70406eaa33520208e1792b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ad23bc3f72423fbc22529462a88f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e256b6272d4c402790d04de9dc8cc47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f5e354f0ec468b800c0d33ddd87aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f7a779da8046bda7dd326c8e3333fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3741ff86aa524da399e54e1130753fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7496cda24cdf458c881ab68758f16c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa9c3e7c4064f71a0246810ae45eb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c719ed6dba5f4552a1f20bd6acb0c3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c0aff6cf1e495386aa909e19803638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49873e392e86457f8127428a7909da99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Initialize instructor embeddings using the Hugging Face model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "\n",
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe8c52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c8707f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04389806464314461,\n",
       " 0.00768554350361228,\n",
       " -0.009231888689100742,\n",
       " 0.024496259167790413,\n",
       " 0.033592283725738525]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfbcf7",
   "metadata": {},
   "source": [
    "# Step 3 : Vector store using FAISS (Vector Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804159fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu) (1.23.5)\n",
      "Using cached faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000217C269A9D0>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/d3/ad/63eb31be05c38445781caecbc6d3b9dec151012194b00573ba34f29d5cf5/faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata\n"
     ]
    }
   ],
   "source": [
    "# !pip install faiss-cpu\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=data,\n",
    "                                 embedding=instructor_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8dcfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
